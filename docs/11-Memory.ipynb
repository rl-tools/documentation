{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "403cfae0-a11f-4844-b6f6-57d0d89cfeaf",
   "metadata": {},
   "source": [
    "# Memory\n",
    "\n",
    "In many real-world scenarios we do not have access to the ground truth state of the environment. In these cases we only get observations that have some mutual information with the true state. In this case the Markov property is violated (we are dealing with a  [POMDP](https://en.wikipedia.org/wiki/Partially_observable_Markov_decision_process>) and hence information from past observations influences the estimate of the current state. Because the belief about the current state is dependent on previous observations, also the future behavior and action selection decision are dependent on them.\n",
    "\n",
    "To respect this in our policy, it needs to be able to reason about sequences of observations. A natural way to implement this is using recurrent neural networs (RNNs) that carry an internal state that can transport information through time.\n",
    "\n",
    "RLtools initially only supports the [GRU (Gated Recurrent Unit)](https://en.wikipedia.org/wiki/Gated_recurrent_unit), a widely used and time-tested RNN architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd3b2a63-014b-4466-9f10-f268a3cc233b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <vector>\n",
    "#include <algorithm>\n",
    "#include <numeric>\n",
    "#include <iostream>\n",
    "\n",
    "#define RL_TOOLS_BACKEND_ENABLE_OPENBLAS\n",
    "#include <rl_tools/operations/cpu_mux.h>\n",
    "#include <rl_tools/nn/optimizers/adam/instance/operations_generic.h>\n",
    "#include <rl_tools/nn/operations_cpu_mux.h>\n",
    "#include <rl_tools/nn/layers/gru/operations_generic.h>\n",
    "#include <rl_tools/nn_models/sequential/operations_generic.h>\n",
    "#include <rl_tools/nn/optimizers/adam/operations_generic.h>\n",
    "#include <rl_tools/nn/loss_functions/mse/operations_generic.h>\n",
    "namespace rlt = rl_tools;\n",
    "#pragma cling load(\"openblas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c335c55-ab11-42d2-9f7b-d565e809f226",
   "metadata": {},
   "outputs": [],
   "source": [
    "using T = float;\n",
    "using DEVICE = rlt::devices::DEVICE_FACTORY<rlt::devices::DefaultCPUSpecification>;\n",
    "using RNG = DEVICE::SPEC::RANDOM::ENGINE<>;\n",
    "using TI = typename DEVICE::index_t;\n",
    "constexpr bool DYNAMIC_ALLOCATION = true;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bd081ce-3e1e-4df2-ade5-41ff60717978",
   "metadata": {},
   "outputs": [],
   "source": [
    "constexpr TI SEQUENCE_LENGTH = 10;\n",
    "constexpr TI BATCH_SIZE = 10;\n",
    "constexpr TI INPUT_DIM = 1;\n",
    "constexpr TI HIDDEN_DIM = 8;\n",
    "constexpr TI OUTPUT_DIM = 1;\n",
    "using INPUT_SHAPE = rlt::tensor::Shape<TI, SEQUENCE_LENGTH, BATCH_SIZE, INPUT_DIM>;\n",
    "using GRU_CONFIG = rlt::nn::layers::gru::Configuration<T, TI, HIDDEN_DIM, rlt::nn::parameters::groups::Normal, DYNAMIC_ALLOCATION>;\n",
    "using GRU = rlt::nn::layers::gru::BindConfiguration<GRU_CONFIG>;\n",
    "using OUTPUT_LAYER_CONFIG = rlt::nn::layers::dense::Configuration<T, TI, OUTPUT_DIM, rlt::nn::activation_functions::IDENTITY>;\n",
    "using OUTPUT_LAYER = rlt::nn::layers::dense::BindConfiguration<OUTPUT_LAYER_CONFIG>;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25d8268d-5ce2-4ffd-a574-5dc3a1b60988",
   "metadata": {},
   "outputs": [],
   "source": [
    "template <typename T_CONTENT, typename T_NEXT_MODULE = rlt::nn_models::sequential::OutputModule>\n",
    "using Module = typename rlt::nn_models::sequential::Module<T_CONTENT, T_NEXT_MODULE>;\n",
    "\n",
    "using MODULE_CHAIN = Module<GRU, Module<OUTPUT_LAYER>>;\n",
    "using CAPABILITY = rlt::nn::capability::Gradient<rlt::nn::parameters::Adam>;\n",
    "using MODEL = rlt::nn_models::sequential::Build<CAPABILITY, MODULE_CHAIN, INPUT_SHAPE>;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ea581ab-039f-4cfd-8c24-24bfa9add4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct ADAM_PARAMS: rlt::nn::optimizers::adam::DEFAULT_PARAMETERS_TENSORFLOW<T>{\n",
    "    static constexpr T ALPHA = 0.003;\n",
    "};\n",
    "using ADAM_SPEC = rlt::nn::optimizers::adam::Specification<T, TI, ADAM_PARAMS>;\n",
    "using OPTIMIZER = rlt::nn::optimizers::Adam<ADAM_SPEC>;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83d3788e-98b6-498e-9315-1a20a2fde77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: OPENBLAS_NUM_THREADS is not set to 1. This may degrade performance.\n"
     ]
    }
   ],
   "source": [
    "constexpr TI DATASET_SIZE = 1000;\n",
    "constexpr TI TESTSET_SIZE = 100;\n",
    "\n",
    "DEVICE device;\n",
    "RNG rng;\n",
    "MODEL model;\n",
    "MODEL::Buffer<> buffer;\n",
    "using TEST_MODEL_TMP = MODEL::template CHANGE_BATCH_SIZE<TI, TESTSET_SIZE>; // inference only model with test set as batch size\n",
    "using TEST_MODEL = TEST_MODEL_TMP::template CHANGE_CAPABILITY<rlt::nn::capability::Forward<>>;\n",
    "TEST_MODEL test_model;\n",
    "TEST_MODEL::Buffer<> test_buffer;\n",
    "MODEL::State<> state;\n",
    "OPTIMIZER optimizer;\n",
    "rlt::Tensor<rlt::tensor::Specification<T, TI, MODEL::INPUT_SHAPE>> input;\n",
    "rlt::Tensor<rlt::tensor::Specification<T, TI, MODEL::OUTPUT_SHAPE>> output_target, d_output;\n",
    "\n",
    "using DATASET_SHAPE = rlt::tensor::Shape<TI, DATASET_SIZE, SEQUENCE_LENGTH, INPUT_DIM>;\n",
    "using DATASET_TARGET_SHAPE = rlt::tensor::Shape<TI, DATASET_SIZE, SEQUENCE_LENGTH, OUTPUT_DIM>;\n",
    "rlt::Tensor<rlt::tensor::Specification<T, TI, DATASET_SHAPE>> dataset_X;\n",
    "rlt::Tensor<rlt::tensor::Specification<T, TI, DATASET_TARGET_SHAPE>> dataset_y;\n",
    "\n",
    "using TESTSET_SHAPE = rlt::tensor::Shape<TI, TESTSET_SIZE, SEQUENCE_LENGTH, INPUT_DIM>;\n",
    "using TESTSET_TARGET_SHAPE = rlt::tensor::Shape<TI, TESTSET_SIZE, SEQUENCE_LENGTH, OUTPUT_DIM>;\n",
    "rlt::Tensor<rlt::tensor::Specification<T, TI, TESTSET_SHAPE>> testset_X;\n",
    "rlt::Tensor<rlt::tensor::Specification<T, TI, TESTSET_TARGET_SHAPE>> testset_y;\n",
    "using TESTSET_SHAPE_PERMUTED = rlt::tensor::Shape<TI, SEQUENCE_LENGTH, TESTSET_SIZE, INPUT_DIM>;\n",
    "using TESTSET_TARGET_SHAPE_PERMUTED = rlt::tensor::Shape<TI, SEQUENCE_LENGTH, TESTSET_SIZE, OUTPUT_DIM>;\n",
    "rlt::Tensor<rlt::tensor::Specification<T, TI, TESTSET_SHAPE_PERMUTED>> testset_X_permuted;\n",
    "rlt::Tensor<rlt::tensor::Specification<T, TI, TESTSET_TARGET_SHAPE_PERMUTED>> testset_y_permuted;\n",
    "rlt::Tensor<rlt::tensor::Specification<T, TI, TESTSET_TARGET_SHAPE_PERMUTED>> testset_output_permuted;\n",
    "\n",
    "rlt::init(device);\n",
    "rlt::malloc(device, rng);\n",
    "constexpr TI SEED = 0;\n",
    "rlt::init(device, rng, SEED);\n",
    "rlt::malloc(device, model);\n",
    "rlt::malloc(device, test_model);\n",
    "rlt::malloc(device, buffer);\n",
    "rlt::malloc(device, test_buffer);\n",
    "rlt::malloc(device, state);\n",
    "rlt::malloc(device, optimizer);\n",
    "rlt::malloc(device, input);\n",
    "rlt::malloc(device, output_target);\n",
    "rlt::malloc(device, d_output);\n",
    "rlt::malloc(device, dataset_X);\n",
    "rlt::malloc(device, dataset_y);\n",
    "rlt::malloc(device, testset_X);\n",
    "rlt::malloc(device, testset_y);\n",
    "rlt::malloc(device, testset_X_permuted);\n",
    "rlt::malloc(device, testset_y_permuted);\n",
    "rlt::malloc(device, testset_output_permuted);\n",
    "rlt::init_weights(device, model, rng);\n",
    "rlt::reset_optimizer_state(device, optimizer, model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2ba5600-693d-4d2d-9a21-ff9c66c681c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "template <typename DATASET_X, typename DATASET_Y>\n",
    "void max_dataset(DATASET_X& dataset_X, DATASET_Y& dataset_y){\n",
    "    static_assert(DATASET_X::SHAPE::FIRST == DATASET_Y::SHAPE::FIRST);\n",
    "    static_assert(DATASET_X::SHAPE::template GET<1> == DATASET_Y::SHAPE::template GET<1>);\n",
    "    rlt::randn(device, dataset_X, rng);\n",
    "    for(TI sample_i = 0; sample_i < DATASET_X::SHAPE::FIRST; sample_i++){\n",
    "        T max;\n",
    "        bool max_set = false;\n",
    "        for(TI step_i = 0; step_i < DATASET_X::SHAPE::template GET<1>; step_i++){\n",
    "            T el = rlt::get(device, dataset_X, sample_i, step_i, 0);\n",
    "            if(!max_set || el > max){\n",
    "                max_set = true;\n",
    "                max = el;\n",
    "            }\n",
    "            rlt::set(device, dataset_y, max, sample_i, step_i, 0);\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6652e672-fe94-4ac2-8a55-98fd19b25b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dataset(dataset_X, dataset_y);\n",
    "max_dataset(testset_X, testset_y);\n",
    "// models operate on (SEQUENCE_STEP x BATCH_SIZE x FEATURE_DIM) for performance reasons:\n",
    "auto permuted_X = rlt::permute(device, testset_X, rlt::tensor::PermutationSpec<0, 1>{});\n",
    "auto permuted_y = rlt::permute(device, testset_y, rlt::tensor::PermutationSpec<0, 1>{});\n",
    "rlt::copy(device, device, permuted_X, testset_X_permuted);\n",
    "rlt::copy(device, device, permuted_y, testset_y_permuted);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "189c5dd9-ef4b-4bdf-85e7-e2446be1afb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -1.507621e+00\n",
      "   1.071986e+00\n",
      "   8.269271e-01\n",
      "   1.601774e+00\n",
      "  -1.074195e+00\n",
      "  -5.420533e-01\n",
      "  -6.830205e-01\n",
      "   1.492320e+00\n",
      "   6.583855e-02\n",
      "   9.513746e-01\n",
      "\n",
      "  -1.507621e+00\n",
      "   1.071986e+00\n",
      "   1.071986e+00\n",
      "   1.601774e+00\n",
      "   1.601774e+00\n",
      "   1.601774e+00\n",
      "   1.601774e+00\n",
      "   1.601774e+00\n",
      "   1.601774e+00\n",
      "   1.601774e+00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rlt::print(device, rlt::view(device, dataset_X, 0));\n",
    "rlt::print(device, rlt::view(device, dataset_y, 0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2de66bf0-102b-46db-a897-6b02c6d36c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 train loss: 4.026309e-02 test loss: 3.559775e-02\n",
      "Epoch 10 train loss: 1.722529e-02 test loss: 1.540120e-02\n",
      "Epoch 15 train loss: 1.022129e-02 test loss: 7.987553e-03\n",
      "Epoch 20 train loss: 6.953578e-03 test loss: 4.966619e-03\n",
      "Epoch 25 train loss: 5.002954e-03 test loss: 3.588097e-03\n",
      "Epoch 30 train loss: 3.616025e-03 test loss: 2.619849e-03\n",
      "Epoch 35 train loss: 2.852915e-03 test loss: 2.276205e-03\n",
      "Epoch 40 train loss: 2.285772e-03 test loss: 1.623374e-03\n",
      "Epoch 45 train loss: 1.853573e-03 test loss: 1.247458e-03\n",
      "Epoch 50 train loss: 1.495403e-03 test loss: 1.218547e-03\n",
      "Epoch 55 train loss: 1.328354e-03 test loss: 1.133017e-03\n",
      "Epoch 60 train loss: 1.153364e-03 test loss: 1.316995e-03\n",
      "Epoch 65 train loss: 1.080623e-03 test loss: 8.134897e-04\n",
      "Epoch 70 train loss: 9.213265e-04 test loss: 9.398991e-04\n",
      "Epoch 75 train loss: 8.744255e-04 test loss: 1.394223e-03\n",
      "Epoch 80 train loss: 8.876204e-04 test loss: 7.558167e-04\n",
      "Epoch 85 train loss: 8.151167e-04 test loss: 6.435094e-04\n",
      "Epoch 90 train loss: 7.562749e-04 test loss: 7.290478e-04\n",
      "Epoch 95 train loss: 6.210597e-04 test loss: 6.309046e-04\n",
      "Epoch 100 train loss: 5.976068e-04 test loss: 7.673404e-04\n"
     ]
    }
   ],
   "source": [
    "std::vector<TI> indices(DATASET_SIZE);\n",
    "std::iota(indices.begin(), indices.end(), 0); // fill with range 0..DATASET_SIZE\n",
    "constexpr TI N_EPOCH = 100;\n",
    "for(TI epoch_i = 0; epoch_i < N_EPOCH; epoch_i++){\n",
    "    T epoch_loss = 0;\n",
    "    std::shuffle(indices.begin(), indices.end(), rng.engine);\n",
    "    for(TI batch_i = 0; batch_i < DATASET_SIZE / BATCH_SIZE; batch_i++){\n",
    "        for(TI sequence_i = 0; sequence_i < BATCH_SIZE; sequence_i++){\n",
    "            TI index = BATCH_SIZE * batch_i + sequence_i;\n",
    "            auto input_sample = rlt::view(device, input, sequence_i, rlt::tensor::ViewSpec<1>{});\n",
    "            auto output_sample = rlt::view(device, output_target, sequence_i, rlt::tensor::ViewSpec<1>{});\n",
    "            auto dataset_input_sample = rlt::view(device, dataset_X, indices[index], rlt::tensor::ViewSpec<0>{});\n",
    "            auto dataset_output_sample = rlt::view(device, dataset_y, indices[index], rlt::tensor::ViewSpec<0>{});\n",
    "            rlt::copy(device, device, dataset_input_sample, input_sample);\n",
    "            rlt::copy(device, device, dataset_output_sample, output_sample);\n",
    "        }\n",
    "        rlt::forward(device, model, input, buffer, rng);\n",
    "        auto output = rlt::output(device, model);\n",
    "        auto output_matrix_view = rlt::matrix_view(device, output);\n",
    "        auto output_target_matrix_view = rlt::matrix_view(device, output_target);\n",
    "        auto d_output_matrix_view = rlt::matrix_view(device, d_output);\n",
    "        rlt::nn::loss_functions::mse::gradient(device, output_matrix_view, output_target_matrix_view, d_output_matrix_view);\n",
    "        T batch_loss = rlt::nn::loss_functions::mse::evaluate(device, output_matrix_view, output_target_matrix_view); \n",
    "        epoch_loss += batch_loss;\n",
    "        rlt::zero_gradient(device, model);\n",
    "        rlt::backward(device, model, input, d_output, buffer);\n",
    "        rlt::step(device, optimizer, model);\n",
    "    }\n",
    "    epoch_loss /= DATASET_SIZE / BATCH_SIZE;\n",
    "    if((epoch_i+1) % 5 == 0){\n",
    "        rlt::copy(device, device, model, test_model);\n",
    "        rlt::evaluate(device, test_model, testset_X_permuted, testset_output_permuted, test_buffer, rng);\n",
    "        T test_loss = rlt::nn::loss_functions::mse::evaluate(device, testset_output_permuted, testset_y_permuted);\n",
    "        std::cout << \"Epoch \" << (epoch_i+1) << \" train loss: \" << epoch_loss << \" test loss: \" << test_loss << std::endl;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daac2ece-8e9d-4e1f-b19c-2732d22b2741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sequence 0\n",
      "Input => Target ~ Predicted\n",
      "   0.65 =>  0.65 ~  0.66\n",
      "   0.89 =>  0.89 ~  0.88\n",
      "   1.38 =>  1.38 ~  1.37\n",
      "   0.74 =>  1.38 ~  1.37\n",
      "  -1.00 =>  1.38 ~  1.37\n",
      "   0.06 =>  1.38 ~  1.39\n",
      "   0.07 =>  1.38 ~  1.40\n",
      "  -0.98 =>  1.38 ~  1.39\n",
      "   1.20 =>  1.38 ~  1.39\n",
      "   0.12 =>  1.38 ~  1.40\n",
      "Test sequence 1\n",
      "Input => Target ~ Predicted\n",
      "  -0.08 => -0.08 ~ -0.09\n",
      "   0.21 =>  0.21 ~  0.21\n",
      "  -0.19 =>  0.21 ~  0.21\n",
      "  -1.47 =>  0.21 ~  0.21\n",
      "  -0.16 =>  0.21 ~  0.20\n",
      "  -1.06 =>  0.21 ~  0.21\n",
      "  -0.36 =>  0.21 ~  0.21\n",
      "   0.62 =>  0.62 ~  0.60\n",
      "   0.31 =>  0.62 ~  0.61\n",
      "  -0.30 =>  0.62 ~  0.63\n",
      "Test sequence 2\n",
      "Input => Target ~ Predicted\n",
      "   1.29 =>  1.29 ~  1.32\n",
      "   0.08 =>  1.29 ~  1.30\n",
      "   0.76 =>  1.29 ~  1.30\n",
      "   0.14 =>  1.29 ~  1.31\n",
      "   0.43 =>  1.29 ~  1.32\n",
      "  -1.59 =>  1.29 ~  1.32\n",
      "  -0.13 =>  1.29 ~  1.32\n",
      "  -0.30 =>  1.29 ~  1.33\n",
      "  -0.64 =>  1.29 ~  1.32\n",
      "   1.25 =>  1.29 ~  1.34\n",
      "Test sequence 3\n",
      "Input => Target ~ Predicted\n",
      "  -0.44 => -0.44 ~ -0.44\n",
      "   0.62 =>  0.62 ~  0.63\n",
      "  -0.06 =>  0.62 ~  0.64\n",
      "   1.33 =>  1.33 ~  1.34\n",
      "   1.23 =>  1.33 ~  1.36\n",
      "   0.40 =>  1.33 ~  1.37\n",
      "   0.32 =>  1.33 ~  1.38\n",
      "  -0.11 =>  1.33 ~  1.38\n",
      "  -0.75 =>  1.33 ~  1.38\n",
      "   0.25 =>  1.33 ~  1.38\n",
      "Test sequence 4\n",
      "Input => Target ~ Predicted\n",
      "  -0.10 => -0.10 ~ -0.11\n",
      "   0.17 =>  0.17 ~  0.17\n",
      "   0.01 =>  0.17 ~  0.19\n",
      "   0.66 =>  0.66 ~  0.65\n",
      "   0.79 =>  0.79 ~  0.80\n",
      "  -0.81 =>  0.79 ~  0.81\n",
      "  -0.85 =>  0.79 ~  0.82\n",
      "  -0.19 =>  0.79 ~  0.83\n",
      "   0.05 =>  0.79 ~  0.83\n",
      "   0.55 =>  0.79 ~  0.82\n"
     ]
    }
   ],
   "source": [
    "std::cout << std::fixed << std::setprecision(2); // fixed point printing\n",
    "for(TI sequence_i = 0; sequence_i < 5; sequence_i++){\n",
    "    std::cout << \"Test sequence \" << sequence_i << std::endl;\n",
    "    std::cout << \"Input => Target ~ Predicted\" << std::endl;\n",
    "    for(TI step_i = 0; step_i < SEQUENCE_LENGTH; step_i++){\n",
    "        std::cout << \"  \" << std::setw(5) << rlt::get(device, testset_X_permuted, step_i, sequence_i, 0);\n",
    "        std::cout << \" => \" << std::setw(5) << rlt::get(device, testset_y_permuted, step_i, sequence_i, 0);\n",
    "        std::cout << \" ~ \" << std::setw(5) << rlt::get(device, testset_output_permuted, step_i, sequence_i, 0);\n",
    "        std::cout << std::endl;\n",
    "    }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++17",
   "language": "C++17",
   "name": "xcpp17"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
