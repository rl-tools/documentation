{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a72b41c8-47b2-4e86-b0b4-25c040adb89f",
   "metadata": {},
   "source": [
    "# Memory\n",
    "\n",
    "In many real-world scenarios we do not have access to the ground truth state of the environment. In these cases we only get observations that have some mutual information with the true state. In this case the Markov property is violated because we are dealing with a  [POMDP](https://en.wikipedia.org/wiki/Partially_observable_Markov_decision_process) and hence information from past observations influences the estimate of the current state. Because the belief about the current state is dependent on previous observations, also the future behavior and action selection decision are dependent on them.\n",
    "\n",
    "To respect this in our policy, it needs to be able to reason about sequences of observations. A natural way to implement this is using recurrent neural networs (RNNs) that carry an internal state that can transport information through time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c062cdd5-1265-49f6-8ba6-072fd0c8fe83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#define RL_TOOLS_BACKEND_ENABLE_OPENBLAS\n",
    "#include <rl_tools/operations/cpu_mux.h>\n",
    "#include <rl_tools/nn/optimizers/adam/instance/operations_generic.h>\n",
    "#include <rl_tools/nn/operations_cpu.h>\n",
    "#include <rl_tools/nn/layers/gru/operations_generic.h>\n",
    "#include <rl_tools/nn/layers/sample_and_squash/operations_generic.h>\n",
    "#include <rl_tools/rl/environments/memory/operations_cpu.h>\n",
    "#include <rl_tools/rl/environments/pendulum/operations_cpu.h>\n",
    "#include <rl_tools/nn_models/mlp/operations_generic.h>\n",
    "#include <rl_tools/nn_models/random_uniform/operations_generic.h>\n",
    "#include <rl_tools/nn_models/sequential/operations_generic.h>\n",
    "#include <rl_tools/nn/optimizers/adam/operations_generic.h>\n",
    "\n",
    "#include <rl_tools/rl/algorithms/sac/loop/core/config.h>\n",
    "#include <rl_tools/rl/loop/steps/evaluation/config.h>\n",
    "#include <rl_tools/rl/loop/steps/timing/config.h>\n",
    "#include <rl_tools/rl/algorithms/sac/loop/core/operations_generic.h>\n",
    "#include <rl_tools/rl/loop/steps/extrack/operations_cpu.h>\n",
    "#include <rl_tools/rl/loop/steps/evaluation/operations_generic.h>\n",
    "#include <rl_tools/rl/loop/steps/checkpoint/operations_cpu.h>\n",
    "#include <rl_tools/rl/loop/steps/save_trajectories/operations_cpu.h>\n",
    "#include <rl_tools/rl/loop/steps/timing/operations_cpu.h>\n",
    "\n",
    "namespace rlt = rl_tools;\n",
    "\n",
    "using DEVICE = rlt::devices::DEVICE_FACTORY<>;\n",
    "using RNG = DEVICE::SPEC::RANDOM::ENGINE<>;\n",
    "using T = float;\n",
    "using TI = typename DEVICE::index_t;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e49374d2-4a14-4db9-9768-575e6ac1127f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pragma cling load(\"openblas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b3c4729-fdac-45dc-942c-9c918f43d7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "constexpr bool MEMORY = true;\n",
    "constexpr bool MEMORY_LONG = false;\n",
    "\n",
    "constexpr TI SEQUENCE_LENGTH = MEMORY ? (MEMORY_LONG ? 500 : 50) : 10;\n",
    "constexpr TI SEQUENCE_LENGTH_PROXY = SEQUENCE_LENGTH;\n",
    "constexpr TI BATCH_SIZE = MEMORY ? 4: 100;\n",
    "constexpr TI NUM_CHECKPOINTS = 100;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "497e19f5-69b0-4d66-b515-f6928a91979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct ENVIRONMENT_PARAMETERS{\n",
    "    static constexpr TI HORIZON = MEMORY_LONG ? 100 : 10;\n",
    "    static constexpr T INPUT_PROBABILITY = HORIZON <= 4 ? 0.5 : (T)2/HORIZON;\n",
    "    static constexpr TI EPISODE_STEP_LIMIT = 2000;\n",
    "    static constexpr rlt::rl::environments::memory::Mode MODE = rlt::rl::environments::memory::Mode::COUNT_INPUT;\n",
    "};\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db6322a7-0aa0-4fba-b776-4bdcc3da7fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "using MEMORY_ENVIRONMENT_SPEC = rlt::rl::environments::memory::Specification<T, TI, ENVIRONMENT_PARAMETERS>;\n",
    "using MEMORY_ENVIRONMENT = rlt::rl::environments::Memory<MEMORY_ENVIRONMENT_SPEC>;\n",
    "using PENDULUM_ENVIRONMENT_SPEC = rlt::rl::environments::pendulum::Specification<T, TI, rlt::rl::environments::pendulum::DefaultParameters<T>>;\n",
    "using PENDULUM_ENVIRONMENT = rlt::rl::environments::Pendulum<PENDULUM_ENVIRONMENT_SPEC>;\n",
    "\n",
    "using ENVIRONMENT = rlt::utils::typing::conditional_t<MEMORY, MEMORY_ENVIRONMENT, PENDULUM_ENVIRONMENT>;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67c0f457-6c27-46fe-96b8-d5e5ad83c32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct LOOP_CORE_PARAMETERS: rlt::rl::algorithms::sac::loop::core::DefaultParameters<T, TI, ENVIRONMENT>{\n",
    "    struct SAC_PARAMETERS: rlt::rl::algorithms::sac::DefaultParameters<T, TI, ENVIRONMENT::ACTION_DIM>{\n",
    "        static constexpr T GAMMA = MEMORY ? 0.0 : 0.99;\n",
    "        static constexpr TI ACTOR_BATCH_SIZE = BATCH_SIZE;\n",
    "        static constexpr TI CRITIC_BATCH_SIZE = BATCH_SIZE;\n",
    "        static constexpr TI SEQUENCE_LENGTH = SEQUENCE_LENGTH_PROXY;\n",
    "        static constexpr TI CRITIC_TRAINING_INTERVAL = 1;\n",
    "        static constexpr TI ACTOR_TRAINING_INTERVAL = 2;\n",
    "        static constexpr bool ENTROPY_BONUS = true;\n",
    "        static constexpr bool ENTROPY_BONUS_NEXT_STEP = false;\n",
    "\n",
    "        static constexpr T TARGET_ENTROPY = MEMORY ? -4 : -1;\n",
    "        static constexpr T ALPHA = 1;\n",
    "        static constexpr bool ADAPTIVE_ALPHA = true;\n",
    "    };\n",
    "    static constexpr TI N_WARMUP_STEPS = 1000;\n",
    "    static constexpr TI N_WARMUP_STEPS_CRITIC = 1000;\n",
    "    static constexpr TI N_WARMUP_STEPS_ACTOR = MEMORY ? 10000: 1000;\n",
    "    static constexpr TI STEP_LIMIT = 200000;\n",
    "    static constexpr TI REPLAY_BUFFER_CAP = STEP_LIMIT;\n",
    "    static constexpr TI ACTOR_HIDDEN_DIM = MEMORY ? (MEMORY_LONG ? 64 : 16) : 32;\n",
    "    static constexpr TI ACTOR_NUM_LAYERS = 4;\n",
    "    static constexpr auto ACTOR_ACTIVATION_FUNCTION = rlt::nn::activation_functions::ActivationFunction::TANH;\n",
    "    static constexpr TI CRITIC_HIDDEN_DIM = ACTOR_HIDDEN_DIM;\n",
    "    static constexpr TI CRITIC_NUM_LAYERS = 4;\n",
    "    static constexpr auto CRITIC_ACTIVATION_FUNCTION = ACTOR_ACTIVATION_FUNCTION;\n",
    "    static constexpr bool SHARED_BATCH = false;\n",
    "    static constexpr TI N_ENVIRONMENTS = 1;\n",
    "\n",
    "    struct BATCH_SAMPLING_PARAMETERS{\n",
    "        static constexpr bool INCLUDE_FIRST_STEP_IN_TARGETS = true;\n",
    "        static constexpr bool ALWAYS_SAMPLE_FROM_INITIAL_STATE = false;\n",
    "        static constexpr bool RANDOM_SEQ_LENGTH = true;\n",
    "        static constexpr bool ENABLE_NOMINAL_SEQUENCE_LENGTH_PROBABILITY = true;\n",
    "        static constexpr T NOMINAL_SEQUENCE_LENGTH_PROBABILITY = 0.5;\n",
    "    };\n",
    "\n",
    "    struct ACTOR_OPTIMIZER_PARAMETERS: rlt::nn::optimizers::adam::DEFAULT_PARAMETERS_TENSORFLOW<T>{\n",
    "        static constexpr T ALPHA = 1e-4;\n",
    "        static constexpr bool ENABLE_BIAS_LR_FACTOR = false;\n",
    "        static constexpr T BIAS_LR_FACTOR = 1;\n",
    "    };\n",
    "    struct CRITIC_OPTIMIZER_PARAMETERS: rlt::nn::optimizers::adam::DEFAULT_PARAMETERS_TENSORFLOW<T>{\n",
    "        static constexpr T ALPHA = 1e-3;\n",
    "        static constexpr bool ENABLE_BIAS_LR_FACTOR = false;\n",
    "        static constexpr T BIAS_LR_FACTOR = 1;\n",
    "    };\n",
    "    struct ALPHA_OPTIMIZER_PARAMETERS: rlt::nn::optimizers::adam::DEFAULT_PARAMETERS_TENSORFLOW<T>{\n",
    "        static constexpr T ALPHA = 1e-3;\n",
    "        static constexpr bool ENABLE_BIAS_LR_FACTOR = false;\n",
    "        static constexpr T BIAS_LR_FACTOR = 1;\n",
    "    };\n",
    "};\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "806d764f-3bca-4203-8dd2-eb334fce0e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "using RNG = DEVICE::SPEC::RANDOM::ENGINE<>;\n",
    "using LOOP_CORE_CONFIG = rlt::rl::algorithms::sac::loop::core::Config<T, TI, RNG, ENVIRONMENT, LOOP_CORE_PARAMETERS, rlt::rl::algorithms::sac::loop::core::ConfigApproximatorsGRU>;\n",
    "using LOOP_EXTRACK_CONFIG = rlt::rl::loop::steps::extrack::Config<LOOP_CORE_CONFIG>;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c88376a9-cba6-4e81-9097-57c21125676a",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct LOOP_EVAL_PARAMETERS: rlt::rl::loop::steps::evaluation::Parameters<T, TI, LOOP_EXTRACK_CONFIG>{\n",
    "    static constexpr TI EVALUATION_INTERVAL = 1000;\n",
    "    static constexpr TI NUM_EVALUATION_EPISODES = 10;\n",
    "    static constexpr TI N_EVALUATIONS = LOOP_CORE_CONFIG::CORE_PARAMETERS::STEP_LIMIT / EVALUATION_INTERVAL;\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2105346-85ca-40f3-a63f-eaa97f432a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LOOP_EVAL_CONFIG = rlt::rl::loop::steps::evaluation::Config<LOOP_EXTRACK_CONFIG, LOOP_EVAL_PARAMETERS>;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef36354a-4503-49b1-a2bf-07d684b1ed20",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct LOOP_CHECKPOINT_PARAMETERS: rlt::rl::loop::steps::checkpoint::Parameters<T, TI>{\n",
    "    static constexpr TI CHECKPOINT_INTERVAL_TEMP = LOOP_CORE_CONFIG::CORE_PARAMETERS::STEP_LIMIT / NUM_CHECKPOINTS;\n",
    "    static constexpr TI CHECKPOINT_INTERVAL = CHECKPOINT_INTERVAL_TEMP == 0 ? 1 : CHECKPOINT_INTERVAL_TEMP;\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee74f417-e83b-4eb7-a900-a9160c4846d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LOOP_CHECKPOINT_CONFIG = rlt::rl::loop::steps::checkpoint::Config<LOOP_EVAL_CONFIG, LOOP_CHECKPOINT_PARAMETERS>;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2e2a668-e442-40e2-b47d-fd44badb38db",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct LOOP_SAVE_TRAJECTORIES_PARAMETERS: rlt::rl::loop::steps::save_trajectories::Parameters<T, TI, LOOP_CHECKPOINT_CONFIG>{\n",
    "    static constexpr TI INTERVAL_TEMP = LOOP_CORE_CONFIG::CORE_PARAMETERS::STEP_LIMIT / 10;\n",
    "    static constexpr TI INTERVAL = INTERVAL_TEMP == 0 ? 1 : INTERVAL_TEMP;\n",
    "    static constexpr TI NUM_EPISODES = 10;\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "315dfdaa-78df-49f2-9231-387ff4d860a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LOOP_SAVE_TRAJECTORIES_CONFIG = rlt::rl::loop::steps::save_trajectories::Config<LOOP_CHECKPOINT_CONFIG, LOOP_SAVE_TRAJECTORIES_PARAMETERS>;\n",
    "using LOOP_TIMING_CONFIG = rlt::rl::loop::steps::timing::Config<LOOP_SAVE_TRAJECTORIES_CONFIG>;\n",
    "using LOOP_CONFIG = LOOP_TIMING_CONFIG;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030a35a9-4140-4b79-8004-bdca03811d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: OPENBLAS_NUM_THREADS is not set to 1. This may degrade performance.\n",
      "Seed: 1\n",
      "Extrack Experiment: \"experiments/2025-10-11_06-22-15/no-hash_sequential_algorithm_environment/sac_memory/0001\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count 5 actor_action -0.175485 ❌\n",
      "Count 6 actor_action -0.196689 ❌\n",
      "Count 0 actor_action -0.129703 ❌\n",
      "Count 1 actor_action -0.151617 ❌\n",
      "Count 0 actor_action -0.129954 ❌\n",
      "Count 1 actor_action -0.151858 ❌\n",
      "Count 0 actor_action -0.129913 ❌\n",
      "Count 1 actor_action -0.151818 ❌\n",
      "Count 0 actor_action -0.130264 ❌\n",
      "Count 1 actor_action -0.152157 ❌\n",
      "Count 1 actor_action -0.133836 ❌\n",
      "Count 2 actor_action -0.155762 ❌\n",
      "Count 0 actor_action -0.129702 ❌\n",
      "Count 1 actor_action -0.151616 ❌\n",
      "Count 2 actor_action -0.142455 ❌\n",
      "Count 3 actor_action -0.16451 ❌\n",
      "Count 2 actor_action -0.148916 ❌\n",
      "Count 3 actor_action -0.170926 ❌\n",
      "Count 2 actor_action -0.135248 ❌\n",
      "Count 3 actor_action -0.157141 ❌\n",
      "Description written to: \"experiments/2025-10-11_06-22-15/no-hash_sequential_algorithm_environment/sac_memory/0001/description.txt\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving Trajectories to: \"experiments/2025-10-11_06-22-15/no-hash_sequential_algorithm_environment/sac_memory/0001/steps/000000000000000/trajectories.json\"\n",
      "Checkpointing to: \"experiments/2025-10-11_06-22-15/no-hash_sequential_algorithm_environment/sac_memory/0001/steps/000000000000000/checkpoint.h\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0/200000 Mean return: -6956.41 Mean episode length: 2000\n",
      "Count 2 actor_action -0.137958 ❌\n",
      "Count 3 actor_action -0.159942 ❌\n",
      "Count 0 actor_action -0.131179 ❌\n",
      "Count 1 actor_action -0.153038 ❌\n",
      "Count 0 actor_action -0.12979 ❌\n",
      "Count 1 actor_action -0.151701 ❌\n",
      "Count 0 actor_action -0.129805 ❌\n",
      "Count 1 actor_action -0.151715 ❌\n",
      "Count 3 actor_action -0.14474 ❌\n",
      "Count 4 actor_action -0.166892 ❌\n",
      "Count 0 actor_action -0.130641 ❌\n",
      "Count 1 actor_action -0.152521 ❌\n",
      "Count 2 actor_action -0.137927 ❌\n",
      "Count 3 actor_action -0.159912 ❌\n",
      "Count 2 actor_action -0.155638 ❌\n",
      "Count 3 actor_action -0.176984 ❌\n",
      "Count 1 actor_action -0.138334 ❌\n",
      "Count 2 actor_action -0.160392 ❌\n",
      "Count 1 actor_action -0.131271 ❌\n",
      "Count 2 actor_action -0.153134 ❌\n",
      "Step: 1000/200000 Mean return: -6700.21 Mean episode length: 2000\n",
      "Loop step: 1098, env step: 1098, SPS: 109.749 (elapsed: 10.004 s)\n",
      "Loop step: 1237, env step: 1237, SPS: 13.8175 (elapsed: 20.064 s)\n",
      "Loop step: 1379, env step: 1379, SPS: 14.1694 (elapsed: 30.085 s)\n",
      "Loop step: 1522, env step: 1522, SPS: 14.2715 (elapsed: 40.105 s)\n",
      "Loop step: 1665, env step: 1665, SPS: 14.2419 (elapsed: 50.146 s)\n",
      "Loop step: 1808, env step: 1808, SPS: 14.2104 (elapsed: 60.209 s)\n",
      "Loop step: 1947, env step: 1947, SPS: 13.8391 (elapsed: 70.253 s)\n",
      "Count 2 actor_action -0.153628 ❌\n",
      "Count 3 actor_action -0.17495 ❌\n",
      "Count 3 actor_action -0.160414 ❌\n",
      "Count 4 actor_action -0.181731 ❌\n",
      "Count 2 actor_action -0.145015 ❌\n",
      "Count 3 actor_action -0.166957 ❌\n",
      "Count 0 actor_action -0.1302 ❌\n",
      "Count 1 actor_action -0.152093 ❌\n",
      "Count 0 actor_action -0.129946 ❌\n",
      "Count 1 actor_action -0.151851 ❌\n",
      "Count 2 actor_action -0.135901 ❌\n",
      "Count 3 actor_action -0.157832 ❌\n",
      "Count 4 actor_action -0.141404 ❌\n",
      "Count 5 actor_action -0.163423 ❌\n",
      "Count 0 actor_action -0.130373 ❌\n",
      "Count 1 actor_action -0.152264 ❌\n",
      "Count 1 actor_action -0.131773 ❌\n",
      "Count 2 actor_action -0.153652 ❌\n",
      "Count 1 actor_action -0.131628 ❌\n",
      "Count 2 actor_action -0.153487 ❌\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpointing to: \"experiments/2025-10-11_06-22-15/no-hash_sequential_algorithm_environment/sac_memory/0001/steps/000000000002000/checkpoint.h\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 2000/200000 Mean return: -6810.38 Mean episode length: 2000\n",
      "Loop step: 2072, env step: 2072, SPS: 12.4968 (elapsed: 80.256 s)\n",
      "Loop step: 2214, env step: 2214, SPS: 14.1397 (elapsed: 90.298 s)\n",
      "Loop step: 2355, env step: 2355, SPS: 14.0492 (elapsed: 100.335 s)\n",
      "Loop step: 2497, env step: 2497, SPS: 14.1603 (elapsed: 110.363 s)\n",
      "Loop step: 2616, env step: 2616, SPS: 11.8923 (elapsed: 120.369 s)\n",
      "Loop step: 2718, env step: 2718, SPS: 10.1474 (elapsed: 130.421 s)\n",
      "Loop step: 2819, env step: 2819, SPS: 10.0836 (elapsed: 140.437 s)\n",
      "Loop step: 2918, env step: 2918, SPS: 9.81799 (elapsed: 150.521 s)\n",
      "Count 1 actor_action -0.131157 ❌\n",
      "Count 2 actor_action -0.153027 ❌\n",
      "Count 0 actor_action -0.129665 ❌\n",
      "Count 1 actor_action -0.151582 ❌\n",
      "Count 0 actor_action -0.129692 ❌\n",
      "Count 1 actor_action -0.151607 ❌\n",
      "Count 1 actor_action -0.132196 ❌\n",
      "Count 2 actor_action -0.154105 ❌\n",
      "Count 2 actor_action -0.134742 ❌\n",
      "Count 3 actor_action -0.156655 ❌\n",
      "Count 1 actor_action -0.14395 ❌\n",
      "Count 2 actor_action -0.165897 ❌\n",
      "Count 1 actor_action -0.149608 ❌\n",
      "Count 2 actor_action -0.170943 ❌\n",
      "Count 0 actor_action -0.130145 ❌\n",
      "Count 1 actor_action -0.152041 ❌\n",
      "Count 2 actor_action -0.150769 ❌\n",
      "Count 3 actor_action -0.172077 ❌\n",
      "Count 3 actor_action -0.142562 ❌\n",
      "Count 4 actor_action -0.164549 ❌\n",
      "Step: 3000/200000 Mean return: -6822.91 Mean episode length: 2000\n",
      "Loop step: 3024, env step: 3024, SPS: 10.5448 (elapsed: 160.573 s)\n",
      "Loop step: 3167, env step: 3167, SPS: 14.2114 (elapsed: 170.635 s)\n",
      "Loop step: 3309, env step: 3309, SPS: 14.1971 (elapsed: 180.638 s)\n",
      "Loop step: 3440, env step: 3440, SPS: 13.016 (elapsed: 190.702 s)\n",
      "Loop step: 3570, env step: 3570, SPS: 12.9778 (elapsed: 200.719 s)\n",
      "Loop step: 3699, env step: 3699, SPS: 12.8611 (elapsed: 210.749 s)\n",
      "Loop step: 3828, env step: 3828, SPS: 12.8493 (elapsed: 220.789 s)\n",
      "Loop step: 3966, env step: 3966, SPS: 13.7233 (elapsed: 230.845 s)\n",
      "Count 2 actor_action -0.134492 ❌\n",
      "Count 3 actor_action -0.156414 ❌\n",
      "Count 0 actor_action -0.129705 ❌\n",
      "Count 1 actor_action -0.15162 ❌\n",
      "Count 1 actor_action -0.131753 ❌\n",
      "Count 2 actor_action -0.153633 ❌\n",
      "Count 3 actor_action -0.144231 ❌\n",
      "Count 4 actor_action -0.166365 ❌\n",
      "Count 1 actor_action -0.13071 ❌\n",
      "Count 2 actor_action -0.152594 ❌\n",
      "Count 1 actor_action -0.130614 ❌\n",
      "Count 2 actor_action -0.152502 ❌\n",
      "Count 1 actor_action -0.150284 ❌\n",
      "Count 2 actor_action -0.171595 ❌\n",
      "Count 0 actor_action -0.130923 ❌\n",
      "Count 1 actor_action -0.152792 ❌\n",
      "Count 1 actor_action -0.133661 ❌\n",
      "Count 2 actor_action -0.155597 ❌\n",
      "Count 2 actor_action -0.134185 ❌\n",
      "Count 3 actor_action -0.156062 ❌\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpointing to: \"experiments/2025-10-11_06-22-15/no-hash_sequential_algorithm_environment/sac_memory/0001/steps/000000000004000/checkpoint.h\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 4000/200000 Mean return: -6827.07 Mean episode length: 2000\n",
      "Loop step: 4078, env step: 4078, SPS: 11.1553 (elapsed: 240.885 s)\n",
      "Loop step: 4177, env step: 4177, SPS: 9.88301 (elapsed: 250.902 s)\n",
      "Loop step: 4276, env step: 4276, SPS: 9.83199 (elapsed: 260.971 s)\n",
      "Loop step: 4394, env step: 4394, SPS: 11.7024 (elapsed: 271.055 s)\n",
      "Loop step: 4526, env step: 4526, SPS: 13.1188 (elapsed: 281.116 s)\n",
      "Loop step: 4652, env step: 4652, SPS: 12.4923 (elapsed: 291.203 s)\n",
      "Loop step: 4765, env step: 4765, SPS: 11.2369 (elapsed: 301.259 s)\n",
      "Loop step: 4894, env step: 4894, SPS: 12.8628 (elapsed: 311.288 s)\n",
      "Count 0 actor_action -0.129677 ❌\n",
      "Count 1 actor_action -0.151593 ❌\n",
      "Count 2 actor_action -0.140129 ❌\n",
      "Count 3 actor_action -0.162137 ❌\n",
      "Count 3 actor_action -0.141313 ❌\n",
      "Count 4 actor_action -0.163307 ❌\n",
      "Count 3 actor_action -0.148731 ❌\n",
      "Count 4 actor_action -0.170678 ❌\n",
      "Count 1 actor_action -0.143261 ❌\n",
      "Count 2 actor_action -0.165233 ❌\n",
      "Count 2 actor_action -0.141187 ❌\n",
      "Count 3 actor_action -0.163221 ❌\n",
      "Count 3 actor_action -0.153209 ❌\n",
      "Count 4 actor_action -0.17449 ❌\n",
      "Count 4 actor_action -0.157936 ❌\n",
      "Count 5 actor_action -0.179221 ❌\n",
      "Count 3 actor_action -0.138455 ❌\n",
      "Count 4 actor_action -0.160397 ❌\n",
      "Count 2 actor_action -0.13255 ❌\n",
      "Count 3 actor_action -0.154418 ❌\n",
      "Step: 5000/200000 Mean return: -6908.75 Mean episode length: 2000\n",
      "Loop step: 5012, env step: 5012, SPS: 11.7783 (elapsed: 321.306 s)\n",
      "Loop step: 5144, env step: 5144, SPS: 13.1294 (elapsed: 331.36 s)\n",
      "Loop step: 5276, env step: 5276, SPS: 13.1611 (elapsed: 341.39 s)\n",
      "Loop step: 5394, env step: 5394, SPS: 11.7222 (elapsed: 351.456 s)\n",
      "Loop step: 5489, env step: 5489, SPS: 9.4752 (elapsed: 361.482 s)\n",
      "Loop step: 5579, env step: 5579, SPS: 8.98786 (elapsed: 371.496 s)\n",
      "Loop step: 5672, env step: 5672, SPS: 9.27028 (elapsed: 381.528 s)\n",
      "Loop step: 5766, env step: 5766, SPS: 9.38567 (elapsed: 391.543 s)\n",
      "Loop step: 5861, env step: 5861, SPS: 9.42946 (elapsed: 401.618 s)\n",
      "Loop step: 5956, env step: 5956, SPS: 9.40474 (elapsed: 411.719 s)\n",
      "Count 1 actor_action -0.130901 ❌\n",
      "Count 2 actor_action -0.152791 ❌\n",
      "Count 3 actor_action -0.134105 ❌\n",
      "Count 4 actor_action -0.155991 ❌\n",
      "Count 2 actor_action -0.147173 ❌\n",
      "Count 3 actor_action -0.169143 ❌\n",
      "Count 1 actor_action -0.132781 ❌\n",
      "Count 2 actor_action -0.154668 ❌\n",
      "Count 2 actor_action -0.132131 ❌\n",
      "Count 3 actor_action -0.153984 ❌\n",
      "Count 2 actor_action -0.151198 ❌\n",
      "Count 3 actor_action -0.172479 ❌\n",
      "Count 3 actor_action -0.147829 ❌\n",
      "Count 4 actor_action -0.16978 ❌\n",
      "Count 2 actor_action -0.14493 ❌\n",
      "Count 3 actor_action -0.166877 ❌\n",
      "Count 4 actor_action -0.160094 ❌\n",
      "Count 5 actor_action -0.181415 ❌\n",
      "Count 1 actor_action -0.131709 ❌\n",
      "Count 2 actor_action -0.153591 ❌\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpointing to: \"experiments/2025-10-11_06-22-15/no-hash_sequential_algorithm_environment/sac_memory/0001/steps/000000000006000/checkpoint.h\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 6000/200000 Mean return: -6749.4 Mean episode length: 2000\n",
      "Loop step: 6037, env step: 6037, SPS: 8.09868 (elapsed: 421.721 s)\n"
     ]
    }
   ],
   "source": [
    "using LOOP_STATE = LOOP_CONFIG::State<LOOP_CONFIG>;\n",
    "TI seed = 1;\n",
    "DEVICE device;\n",
    "LOOP_STATE ts;\n",
    "ts.extrack_config.name = \"sequential\";\n",
    "ts.extrack_config.population_variates = \"algorithm_environment\";\n",
    "ts.extrack_config.population_values = \"sac_memory\";\n",
    "rlt::malloc(device);\n",
    "rlt::init(device);\n",
    "rlt::malloc(device, ts);\n",
    "rlt::init(device, ts, seed);\n",
    "DEVICE::SPEC::RANDOM::ENGINE<> myrng;\n",
    "rlt::init(device, myrng, seed);\n",
    "bool done = false;\n",
    "while(!done){\n",
    "    if(ts.step % 1000 == 0){\n",
    "        constexpr TI TEST_SEQUENCE_LENGTH = SEQUENCE_LENGTH;\n",
    "        rlt::Tensor<rlt::tensor::Specification<T, TI, rlt::tensor::Shape<TI, TEST_SEQUENCE_LENGTH, 1, 2>>> test_critic_input;\n",
    "        rlt::Tensor<rlt::tensor::Specification<T, TI, rlt::tensor::Shape<TI, TEST_SEQUENCE_LENGTH, 1, 1>>> test_critic_output;\n",
    "        using EVALUATION_ACTOR = decltype(ts.actor_critic.actor)::CHANGE_BATCH_SIZE<TI, 1>;\n",
    "        using EVALUATION_CRITIC = rlt::utils::typing::remove_reference_t<decltype(ts.actor_critic.critics[0])>::CHANGE_BATCH_SIZE<TI, 1>;\n",
    "        EVALUATION_ACTOR::Buffer<1> actor_buffer;\n",
    "        EVALUATION_CRITIC::Buffer<1> critic_buffer;\n",
    "        rlt::malloc(device, test_critic_input);\n",
    "        rlt::malloc(device, test_critic_output);\n",
    "        rlt::malloc(device, actor_buffer);\n",
    "        rlt::malloc(device, critic_buffer);\n",
    "        auto test_actor_input = rlt::view_range(device, test_critic_input, 0, rlt::tensor::ViewSpec<2, 1>{});\n",
    "        auto test_actor_output = rlt::view_range(device, test_critic_input, 1, rlt::tensor::ViewSpec<2, 1>{});\n",
    "        constexpr TI N_EXAMPLES = 10;\n",
    "        TI critic_correct_examples = 0;\n",
    "        TI actor_correct_examples = 0;\n",
    "        for(TI example_i = 0; example_i < N_EXAMPLES; example_i++){\n",
    "            rlt::Mode<rlt::mode::Evaluation<>> mode;\n",
    "            std::vector<TI> values;\n",
    "            if(TEST_SEQUENCE_LENGTH >= 2){\n",
    "                for(TI seq_i = 0; seq_i < TEST_SEQUENCE_LENGTH-1; seq_i++){\n",
    "                    TI value = rlt::random::uniform_real_distribution(device.random, (T)0, (T)1, myrng) < ENVIRONMENT_PARAMETERS::INPUT_PROBABILITY ? 1 : 0;\n",
    "                    values.push_back(value);\n",
    "                    while(values.size() > ENVIRONMENT_PARAMETERS::HORIZON){\n",
    "                        values.erase(values.begin());\n",
    "                    }\n",
    "                    rlt::set(device, test_critic_input, (T)value, seq_i, 0, 0);\n",
    "                }\n",
    "            }\n",
    "\n",
    "//            rlt::Mode<rlt::nn::layers::gru::StepByStepMode<TI, rlt::mode::Evaluation>> mode;\n",
    "//            mode.reset = true;\n",
    "            while(values.size() > ENVIRONMENT_PARAMETERS::HORIZON-1){\n",
    "                values.erase(values.begin());\n",
    "            }\n",
    "            TI pre_count = std::accumulate(values.begin(), values.end(), 0);\n",
    "\n",
    "            for(TI input_i = 0; input_i < 2; input_i++){\n",
    "//                    TI input_i = real_input_i - 1;\n",
    "                rlt::set(device, test_critic_input, (T)input_i, TEST_SEQUENCE_LENGTH-1, 0, 0);\n",
    "                TI count = pre_count + input_i;\n",
    "                // line search\n",
    "                T max_value = 0;\n",
    "                bool max_value_set = false;\n",
    "                TI max_action = 0;\n",
    "                for(TI action_i = 0; action_i < 5; action_i++){\n",
    "                    T action = ((T)action_i)/10;\n",
    "                    rlt::set(device, test_critic_input, action, TEST_SEQUENCE_LENGTH-1, 0, 1);\n",
    "//                    rlt::utils::assert_exit(device, rlt::get(device, test_critic_input, TEST_SEQUENCE_LENGTH-2, 0, 0) + rlt::get(device, test_critic_input, TEST_SEQUENCE_LENGTH-1, 0, 0) == count, \"Count mismatch\");\n",
    "//                    rlt::print(device, test_critic_input);\n",
    "                    rlt::evaluate(device, ts.actor_critic.actor, test_actor_input, test_actor_output, actor_buffer, myrng, mode); // to calculate the missing action\n",
    "                    rlt::evaluate(device, ts.actor_critic.critics[0], test_critic_input, test_critic_output, critic_buffer, myrng, mode);\n",
    "                    T value = rlt::get(device, test_critic_output, TEST_SEQUENCE_LENGTH-1, 0, 0);\n",
    "                    if(!max_value_set || value > max_value){\n",
    "                        max_value = value;\n",
    "                        max_value_set = true;\n",
    "                        max_action = action_i;\n",
    "                    }\n",
    "//                        std::cout << \"Count \" << count << \" action \" << action << \" value: \" << rlt::get(device, test_critic_output, TEST_SEQUENCE_LENGTH-1, 0, 0) << std::endl;\n",
    "                }\n",
    "                critic_correct_examples += max_action == count;\n",
    "//                    std::cout << \"Input \" << input_i << \" max_action \" << max_action << (max_action == count ? \" correct\" : \" incorrect\") << std::endl;\n",
    "                rlt::evaluate(device, ts.actor_critic.actor, test_actor_input, test_actor_output, actor_buffer, myrng, mode);\n",
    "                bool actor_correct = round(rlt::get(device, test_actor_output, TEST_SEQUENCE_LENGTH-1, 0, 0) * 10) == count;\n",
    "                std::cout << \"Count \" << count << \" actor_action \" << rlt::get(device, test_actor_output, TEST_SEQUENCE_LENGTH-1, 0, 0) << (actor_correct ? \" ✅\" : \" ❌\") << std::endl;\n",
    "                actor_correct_examples += actor_correct;\n",
    "            }\n",
    "        }\n",
    "        rlt::add_scalar(device, device.logger, \"critic_evaluation_accuracy\", critic_correct_examples / ((T)2*N_EXAMPLES));\n",
    "        rlt::add_scalar(device, device.logger, \"actor_evaluation_accuracy\", actor_correct_examples / ((T)2*N_EXAMPLES));\n",
    "        rlt::free(device, test_critic_input);\n",
    "        rlt::free(device, test_critic_output);\n",
    "        rlt::free(device, actor_buffer);\n",
    "        rlt::free(device, critic_buffer);\n",
    "    }\n",
    "    done = rlt::step(device, ts);\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea79010-faa6-4077-9192-8b78123b8da2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++17",
   "language": "C++17",
   "name": "xcpp17"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
